{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LGBIO2060_TP3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fblondiaux/LGBIO2060-2020/blob/master/LGBIO2060_TP3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd-uRhH1cmSn"
      },
      "source": [
        "# LGBIO2060 - Exercise session 3\n",
        "Kalman filtering or how to implement the prior and likelihood dynamically? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEi52Hd4c3OE"
      },
      "source": [
        "## Import and helper functions\n",
        "**Please execute the cell below to initialize the notebook environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_He_4QlckhJ",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "!pip install pykalman --quiet\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pykalman\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDxnOtZ78iG5",
        "cellView": "form"
      },
      "source": [
        "#@title Utility functions\n",
        "def plot_my_system(state_evolution):\n",
        "  \"\"\"\n",
        "  Do not edit this function...\n",
        "\n",
        "  the aim of this function is to represent the time-evolution of a dynamical linear system\n",
        "  Author : Antoine de Comite \n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(figsize=(8,6))\n",
        "  xlim = None\n",
        "  ylim = None\n",
        "  ax.scatter(state_evolution[0,:],state_evolution[1,:],c='m',s=100,alpha=0.7)\n",
        "  ax.plot(state_evolution[0,:],state_evolution[1,:],LineWidth=2,c='k')\n",
        "  ax.set_xlabel(\"x_1\")\n",
        "  ax.set_ylabel(\"x_2\")\n",
        "  ax.set(xlim=xlim)\n",
        "  ax.set(ylim=ylim)\n",
        "  plt.plot()\n",
        "  return ax\n",
        "def plot_my_system_with_obs(state_evolution,obs_evolution):\n",
        "  \"\"\"\n",
        "  Do not edit this function...\n",
        "\n",
        "  the aim of this function is to represent the time-evolution of a dynamical linear system\n",
        "  Author : Antoine de Comite \n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(figsize=(8,6))\n",
        "  xlim = None\n",
        "  ylim = None\n",
        "  ax.scatter(state_evolution[0,:],state_evolution[1,:],c='m',s=100,alpha=0.7)\n",
        "  ax.plot(state_evolution[0,:],state_evolution[1,:],LineWidth=2,c='k',label='Latent state')\n",
        "  ax.plot(obs_evolution[0,:],obs_evolution[1,:],LineWidth=2,c='g',label='Observation')\n",
        "  ax.set_xlabel(\"x_1\")\n",
        "  ax.set_ylabel(\"x_2\")\n",
        "  ax.set(xlim=xlim)\n",
        "  ax.set(ylim=ylim)\n",
        "  ax.legend()\n",
        "  plt.plot()\n",
        "  return ax\n",
        "def plot_my_kalman_filter(state_evolution,obs_evolution,estimated_evolution):\n",
        "  \"\"\"\n",
        "  DO NOT EDIT THIS FUNCTION\n",
        "  author : antoine de Comite \n",
        "  \"\"\"\n",
        "\n",
        "  fig,ax = plt.subplots(figsize=(8,6))\n",
        "  xlim = None; ylim = None\n",
        "  ax.scatter(state_evolution[0,:-1],state_evolution[1,:-1],c='m',s=100,alpha=0.7)\n",
        "  ax.plot(state_evolution[0,:-1],state_evolution[1,:-1],LineWidth=2,c='k',label='Latent state')\n",
        "  ax.plot(obs_evolution[0,:-1],obs_evolution[1,:-1],LineWidth=2,c='g',label='Observation')\n",
        "  ax.plot(estimated_evolution[0,:-1],obs_evolution[1,:-1],LineWidth=2,c='r',label='Estimation')\n",
        "  ax.set_xlabel(\"x_1\")\n",
        "  ax.set_ylabel(\"x_2\")\n",
        "  ax.set(xlim=xlim)\n",
        "  ax.set(ylim=ylim)\n",
        "  ax.legend()\n",
        "  plt.plot()\n",
        "  return ax\n",
        "def plot_gaze_data(data, img=None, ax=None):\n",
        "    # overlay gaze on stimulus\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    xlim = None\n",
        "    ylim = None\n",
        "    if img is not None:\n",
        "        ax.imshow(img, aspect='auto')\n",
        "        ylim = (img.shape[0], 0)\n",
        "        xlim = (0, img.shape[1])\n",
        "\n",
        "    ax.scatter(data[:, 0], data[:, 1], c='m', s=100, alpha=0.7)\n",
        "    ax.set(xlim=xlim, ylim=ylim)\n",
        "\n",
        "    return ax\n",
        "def plot_kf_state(kf, data, ax):\n",
        "    mu_0 = np.ones(kf.n_dim_state)\n",
        "    mu_0[:data.shape[1]] = data[0]\n",
        "    kf.initial_state_mean = mu_0\n",
        "\n",
        "    mu, sigma = kf.smooth(data)\n",
        "    ax.plot(mu[:, 0], mu[:, 1], 'limegreen', linewidth=3, zorder=1)\n",
        "    ax.scatter(mu[0, 0], mu[0, 1], c='orange', marker='>', s=200, zorder=2)\n",
        "    ax.scatter(mu[-1, 0], mu[-1, 1], c='orange', marker='s', s=200, zorder=2)\n",
        "import ipywidgets as widgets  # interactive display\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "# use NMA plot style\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n",
        "my_layout = widgets.Layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv2jej0re8Ue",
        "cellView": "form"
      },
      "source": [
        "#@title Data retrieval and loading\n",
        "import io\n",
        "import os\n",
        "import hashlib\n",
        "import requests\n",
        "\n",
        "fname = \"W2D3_mit_eyetracking_2009.npz\"\n",
        "url = \"https://osf.io/jfk8w/download\"\n",
        "expected_md5 = \"20c7bc4a6f61f49450997e381cf5e0dd\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    elif hashlib.md5(r.content).hexdigest() != expected_md5:\n",
        "      print(\"!!! Data download appears corrupted !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n",
        "\n",
        "def load_eyetracking_data(data_fname=fname):\n",
        "\n",
        "  with np.load(data_fname, allow_pickle=True) as dobj:\n",
        "    data = dict(**dobj)\n",
        "\n",
        "  images = [plt.imread(io.BytesIO(stim), format='JPG')\n",
        "            for stim in data['stimuli']]\n",
        "  subjects = data['subjects']\n",
        "\n",
        "  return subjects, images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytv17jb8dhEH"
      },
      "source": [
        "## Tutorial objectives \n",
        "\n",
        "At the end of this tutorial, you should be able to explain the concepts of dynamical system and Kalman filter. You should also be able to use Kalman and EM algorithm on real data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYDwDdw8eMLJ"
      },
      "source": [
        "# Section 1 - Dynamical systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP7Ct3GneUt6"
      },
      "source": [
        "In this tutorial, we will be applying filtering methods to dynamical systems. A dynamical system is a system for which the time-evolution of any point can be described by a time-dependent function. Many systems that we encounter in our daily life are dynamical systems: eyes movements, reaching movements, walking, population dynamics,... \n",
        "\n",
        "\n",
        "A dynamical system can be observed through some noise and uncertainty similarly to a fixed variable (see the first two tutorials). Therefore, in order to obtain the best estimate of the latent state of the system, we can apply Bayes theorem at every time step. This is what we will do in this tutorial.\n",
        "\n",
        "\n",
        "A dynamical system has the following continuous and discrete forms, respectively : \n",
        "\n",
        "\\begin{eqnarray}\n",
        "& & \\\\\n",
        "\\dot{x}\\left(t\\right) & = & A x\\left(t\\right) + \\xi\\left(t\\right)\\\\\n",
        "& & \\\\\n",
        "x\\left[t+1\\right] & = & A x\\left[t\\right] + \\xi\\left[t\\right] \\\\\n",
        "& & \\\\\n",
        "\\end{eqnarray}\n",
        "\n",
        "where $A$ is called the **state-transition matrix** matrix and $\\xi\\left(t\\right)$ is Gaussian white motor noise generated from $\\mathcal{N}\\left(0,\\Omega_{\\text{motor}}\\right)$. $\\Omega_{\\text{motor}}$ is the covariance matrix of the motor noise.\n",
        "\n",
        "The latent state $x$ can have more than one entry, for example we may want to estimate the x- and y-positions of an annoying fly. In this case, the latent state will become a latent state vector $x = \\left[x_1,x_2 \\right]^T$ and the dynamical system can be rewritten : \n",
        "\n",
        "\n",
        "\\begin{eqnarray}\n",
        "&&\\\\\n",
        "\\begin{bmatrix}\n",
        "  x_1[t+1] \\\\\n",
        "  x_2[t+1]\n",
        "  \\end{bmatrix} &=& \\begin{bmatrix}A_{11} & A_{12}\\\\ A_{21} & A_{22} \\end{bmatrix}\\begin{bmatrix}x_1[t]\\\\ x_2[t]\\end{bmatrix} + \\begin{bmatrix}\\xi_1[t] \\\\ \\xi_2[t] \\end{bmatrix}\n",
        "  &&\\\\\n",
        "\\end{eqnarray}\n",
        "\n",
        "**Exercise 1 - Implement a function that defines the system mentionned above**\n",
        "\n",
        "\n",
        "In this first exercise, you are asked to model the the dynamical system characterised by the equation above. \n",
        "\n",
        "\n",
        "Hints : \n",
        "* You can assume that the covariance matrix of the motor noise is diagonal and that all the entries of the diagonal are equal to $\\sigma_{\\text{motor}}$. (see the function np.random.multivariate_normal)\n",
        "* You will be performing matrix multiplications, consider this while implementing your function...\n",
        "* You can use the function *plot_my_system* to represent the time-evolution of your linear dynamical system\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ATpdHNNn-5i"
      },
      "source": [
        "def my_system(nsteps,x0,A,omega_motor,seed=2060):\n",
        "  \"\"\"\n",
        "  my_system is a function that model the time-evolution of a linear dynamical system\n",
        "  with state transition matrix A.\n",
        "  Inputs : nsteps is the number of time steps to model\n",
        "           x0 is the initial state (where we are starting from)\n",
        "           A is the state-transition matrix\n",
        "  Outputs : state_evolution is a numpy array that contains the time-evolution of \n",
        "            the state vector : (state size * nsteps)\n",
        "  \"\"\"\n",
        "  # Set the random generator seed\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  ########################\n",
        "  #### Your code here ####\n",
        "  ########################\n",
        "  return state_evolution\n",
        "\n",
        "# Run the lines below to test your code\n",
        "\n",
        "nsteps = 50\n",
        "x0 = np.array([1,1]).T\n",
        "A = np.array([[1., 1.], [-(2*np.pi/20.)**2., .9]])\n",
        "sigma_motor = 0.05\n",
        "omega_motor = [[sigma_motor , 0],[0, sigma_motor]]\n",
        "\n",
        "state_evolution = my_system(nsteps,x0,A,omega_motor)\n",
        "plot_my_system(state_evolution)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mz1vFOB-XWl"
      },
      "source": [
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/blob/master/Solutions/TP3Sol1.py) for solution.\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=413 height=300 src=https://raw.githubusercontent.com/fblondiaux/LGBIO2060-2020/master/Solutions/TP3-Ex1.png>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nQ__9qRFBLA"
      },
      "source": [
        "**What is the effect of the motor noise covariance on the behaviour of the system?**\n",
        "\n",
        "\n",
        "Play with the widget below to explore this effect. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFwCNuwDArt4"
      },
      "source": [
        "# @title\n",
        "# @markdown Make sure you execute this cell to enable the widget!\n",
        "my_layout.width = '450px'\n",
        "@widgets.interact(\n",
        "    sigma_motor=widgets.FloatSlider(0.05, min=0, max=1, step=0.05, layout=my_layout)\n",
        "\n",
        ")\n",
        "\n",
        "def sigma_motor(sigma_motor = 0.05):\n",
        "    nsteps = 50\n",
        "    x0 = np.array([1,1]).T\n",
        "    A = np.array([[1., 1.], [-(2*np.pi/20.)**2., .9]])\n",
        "    omega_motor = [[sigma_motor , 0],[0, sigma_motor]]\n",
        "    state_evolution = my_system(nsteps,x0,A,omega_motor)\n",
        "    plot_my_system(state_evolution)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "064vvCvAFyQB"
      },
      "source": [
        "---\n",
        "\n",
        "However, as we saw in the previous tutorials, our sensory inputs are not perfect and it is impossible to know the real latent state; we can only get a rough estimate of it. Mathematically, we define the observation of the latent state of our dynamical system, $y[t]$ as follows: \n",
        "\n",
        "\n",
        "$\\begin{eqnarray}\n",
        "& & \\\\\n",
        "y[t]& = & H x[t] + \\eta[t]\\\\\n",
        " & & \\\\\n",
        "\\begin{bmatrix}y_1[t]\\\\ y_2[t]\\end{bmatrix} & = &\\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix} \\begin{bmatrix}x_1[t] \\\\ x_2[t]\\end{bmatrix} + \\begin{bmatrix}\\eta_1[t]\\\\ \\eta_2[t]\\end{bmatrix}\n",
        "& &\\\\\n",
        "\\end{eqnarray}$\n",
        "\n",
        "where $H$ is the observation matrix and $\\eta[t]$ is a vector of Gaussian white sensory noise generated from $\\mathcal{N}\\left(0,\\Omega_{\\text{sensory}}\\right)$. \n",
        "\n",
        "**Exercise 2 - Implement the observation of the latent state**\n",
        "\n",
        "* you can use the function *plot_my_system_with_obs* for the plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEScQ4Geoz08"
      },
      "source": [
        "def my_system_with_obs(nsteps,x0,A,H,omega_motor,omega_sensory):\n",
        "  \"\"\"\n",
        "  my_system_with_obs is a function that model the time-evolution of the latent state \n",
        "  and its observation\n",
        "  Inputs : nsteps is the number of time steps to model\n",
        "           x0 is the initial state (where we are starting from)\n",
        "           A is the state-transition matrix\n",
        "           H is the observation matrix\n",
        "           omega_motor is the variance of the motor noise\n",
        "           sigma_sensory is the variance of the sensory noise\n",
        "  Outputs : state_evolution is a numpy array that contains the time-evolution of \n",
        "            the state vector : (state size * nsteps)\n",
        "            obs_evolution is a numpy array that contains the time-evolution of \n",
        "            the observation of the state vector : (state size * nsteps)\n",
        "  \"\"\"\n",
        "  ######################\n",
        "  ### your code here ###\n",
        "  ######################\n",
        "  \n",
        "  return state_evolution,obs_evolution\n",
        "\n",
        "# Run the lines below to test your code \n",
        "np.random.seed(2060)\n",
        "nsteps = 50\n",
        "x0 = np.array([1,1]).T\n",
        "A = np.array([[1.,1.],[-(2*np.pi/20.)**2.,0.9]])\n",
        "H = np.eye(2)\n",
        "sigma_motor = 0.05\n",
        "sigma_sensory = 0.02\n",
        "omega_motor = [[sigma_motor , 0],[0, sigma_motor]]\n",
        "omega_sensory = [[sigma_sensory , 0],[0, sigma_sensory]]\n",
        "######################\n",
        "### your code here ###\n",
        "######################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8UtFShu_v0J"
      },
      "source": [
        "*Example output:*\n",
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/blob/master/Solutions/TP3Sol2.py) for solution.\n",
        "\n",
        "<img alt='Solution hint' align='left' width=413 height=300 src=https://raw.githubusercontent.com/fblondiaux/LGBIO2060-2020/master/Solutions/TP3-Ex2.png>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "embb74sbOnq7"
      },
      "source": [
        "**Compared to the first and second tutorials, what does the green line correspond to (in terms of Bayes' theorem)?**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMV7buBNxZoj"
      },
      "source": [
        "## Section 2 - Kalman filter or the optimal observation of continuous linear dynamical systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKT61go4IfYT"
      },
      "source": [
        "Once again, our sensory inputs are not good enough to infer the position of the fly we are tracking. In order to have a better estimation of the fly's position at every time, we will use a continuous adaptation of Bayes' theorem: the **Kalman filter**. \n",
        "\n",
        "At every time step, the Kalman filter computes the weighted sum of the prior and the likelihood, weighted by a factor that characterises how trustable each term is. The result of this weighted sum will be the posterior distribution; this posterior distribution is the optimal estimator of the latent state of the system. \n",
        "\n",
        "The estimated state, denoted $\\hat{x}$ is computed this way : \n",
        "\n",
        "$\\begin{eqnarray}\n",
        "& & \\\\\n",
        "\\hat{x}[t] & = & \\text{trust}_{\\text{prior}}x_{\\text{prior}} + \\text{trust}_{\\text{likelihood}}x_{\\text{likelihood}}\\\\\n",
        "& & \\\\\n",
        "\\hat{x}[t+1] & = & A  \\hat{x}[t]+ K[t]\\left(y[t] - H \\hat{x}[t]\\right)\\\\\n",
        "& & \\\\\n",
        "\\end{eqnarray}$\n",
        "\n",
        "Where $K[t]$ is the Kalman gain evaluated at time $t$. These Kalman gains will be the weighting parameters that characterises how much we trust one source of information (prior and likelihood) over the other. Since these gains quantifies the trust we have in each source, they will be computed based on the covariances matrices of these two sources. The covariance matrix related to the prior is $\\Omega_{\\text{motor}}$ and the one related to the likelihood is $\\Omega_{\\text{sensory}}$. Therefore the gain of the kalman filter are recursively computed as follows:  \n",
        "\n",
        "$\\begin{eqnarray}\n",
        "& & \\\\\n",
        "K[t]& = &A\\, \\Sigma[t] \\,H^T \\left(H \\,\\Sigma[T]\\,H^T+\\Omega_{\\text{motor}}\\right)^{-1} \\\\\n",
        "& & \\\\\n",
        "\\Sigma[t+1] & = & \\Omega_{\\text{sensory}} + \\left(A-K[t]\\,H\\right)\\Sigma[T]\\,A^T\n",
        "\\end{eqnarray}$\n",
        "\n",
        "Where $\\Sigma[t] = \\mathbb{C}\\text{ov}\\left\\{\\hat{x}[t]\\right\\}$ is the covariance matrix of the estimated state at time t. \n",
        "\n",
        "\n",
        "**Exercice 3 - Implement the function below to apply Kalman filter to the dynamical linear system**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB-W0jY-87UU"
      },
      "source": [
        "def my_kalman_filter(nsteps,x0,A,H,omega_motor,omega_sensory,seed=2060):\n",
        "  \"\"\"\n",
        "  my_kalman_filter computes and applies the Kalman filter to the system seen above\n",
        "  Inputs : nsteps is the number of time steps to model\n",
        "           x0 is the initial state (where we are starting from)\n",
        "           A is the state-transition matrix\n",
        "           H is the observation matrix\n",
        "  Outputs : latent_state is a numpy array that contains the time-evolution of \n",
        "             the state vector : (state size * nsteps)\n",
        "            observed_state is a numpy array that contains the time-evolution of \n",
        "             the observation of the state vector : (state size * nsteps)\n",
        "            estimated_state is a numpy array that contains the time-evolution of \n",
        "              the estimation of the state vector : (state size * nsteps)\n",
        "            K kalman gains: (state size * state size * nsteps)\n",
        "  \"\"\"\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  K = np.zeros((len(x0),len(x0),nsteps))\n",
        "  Sigma = np.zeros((len(x0),len(x0),nsteps))\n",
        "\n",
        "  ####################\n",
        "  ## your code here ##\n",
        "  ####################\n",
        "  return latent_state,observed_state, estimated_state, K\n",
        "\n",
        "\n",
        "# Run the lines below to test your code\n",
        "\n",
        "# Parameters definition\n",
        "nsteps = 50\n",
        "A = np.array([[1.,1.],[-(2*np.pi/20.)**2.,0.9]])\n",
        "H = np.eye(2)\n",
        "x0 = np.array([1,1]).T\n",
        "omega_motor = 0.05 * np.eye(len(x0))\n",
        "omega_sensory = 0.02 * np.eye(len(x0))\n",
        "\n",
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG0ae8od_2Ee"
      },
      "source": [
        "*Example output:*\n",
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/blob/master/Solutions/TP3Sol3.py) for solution.\n",
        "\n",
        "<img alt='Solution hint' align='left' width=413 height=300 src=https://raw.githubusercontent.com/fblondiaux/LGBIO2060-2020/master/Solutions/TP3-Ex3.png>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oJm_aouB9aB"
      },
      "source": [
        "**Before going to the next section, explore the effect that the initial parameters have on the system (A,H, x0, omega_motor and omega_sensory)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0E0HF9bjfhN"
      },
      "source": [
        "##Section 3 - Application of Kalman to real data\n",
        "\n",
        "Now that we have seen the mathematical ground of Bayesian integration and Kalman filtering, let's take a look at how they can be applied to real data. Tracking gaze is used for both fundamental and clinical research and is therefore a very active research field yet challenging because of the various sources of noise inherent to this kind of measurements. \n",
        "\n",
        "For this example, we will apply this method to a small subset of data from the [MIT Eyetracking Database](http://people.csail.mit.edu/tjudd/WherePeopleLook/index.html) [[Judd et al. 2009](http://people.csail.mit.edu/tjudd/WherePeopleLook/Docs/wherepeoplelook.pdf)]. This data was collected as part of an effort to model [visual saliency](http://www.scholarpedia.org/article/Visual_salience) -- given an image, can we predict where a person is most likely going to look.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlX4b777leeV"
      },
      "source": [
        "# load eyetracking data\n",
        "subjects, images = load_eyetracking_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE4fnjM3llK8"
      },
      "source": [
        "In this dataset, there are three different stimuli (images) and five different subjects. Each subject fixated in the center of the screen before the image appeared, then had a few seconds to freely look around. You can use the widget below to see how different subjects visually scanned the presented image. A subject ID of -1 will show the stimulus image without any overlayed gaze trace. \n",
        "\n",
        "Note that the images are rescaled below for display purposes, they were in their original aspect ratio during the task itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVUzxtPelnBs"
      },
      "source": [
        "#@markdown Make sure you execute this cell to enable the widget\n",
        "\n",
        "@widgets.interact(subject_id=widgets.IntSlider(-1,min=-1,max=4),\n",
        "                  image_id=widgets.IntSlider(0,min=0,max=2))\n",
        "def plot_subject_trace(subject_id=-1, image_id=0):\n",
        "  if subject_id==-1:\n",
        "    subject = np.zeros((3,0,2))\n",
        "  else:\n",
        "    subject = subjects[subject_id]\n",
        "  data = subject[image_id]\n",
        "  img = images[image_id]\n",
        "\n",
        "  fig, ax=plt.subplots()\n",
        "  ax.imshow(img,aspect='auto')\n",
        "  ax.scatter(data[:,0],data[:,1],c='m',s=100,alpha=0.7)\n",
        "  ax.set(xlim=(0, img.shape[1]), ylim=(img.shape[0], 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dVEsOeInHhA"
      },
      "source": [
        "**Fitting data with `pykalman`**\n",
        "\n",
        "\n",
        "Now that we have data, we would like to use Kalman filtering to give us a better estimate of the true gaze. Up until this point we've known the parameters of our linear dynamical system, but here we need to estimate them from data directly. We will use the `pykalman` package to handle this estimation using the EM algorithm.\n",
        "\n",
        "Before exploring fitting models with `pykalman` it's worth pointing out some naming conventions used by the library:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "A &: \\texttt{transition_matrices} & \n",
        "\\Omega_{\\text{motor}} &: \\texttt{transition_covariance}\\\\\n",
        "H &:\\texttt{observation_matrices} &\n",
        "\\Omega_{\\text{sensory}} &:\\texttt{observation_covariance}\\\\\n",
        "\\mu_0 &: \\texttt{initial_state_mean} & \\Sigma_0 &: \\texttt{initial_state_covariance}\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S-Fh9lUoTwL"
      },
      "source": [
        "The first thing we need to do is provide a guess at the dimensionality of the latent state. Let us start by assuming the dynamics line-up directly with the observation data (pixel x,y-coordinates), and so we have a state dimension of 2.\n",
        "\n",
        "We also need to decide which parameters we want the EM algorithm to fit. In this case, we will let the EM algorithm discover the dynamics parameters i.e. the $A$, $\\Omega_{\\text{motor}}$, $H$, and $\\Omega_{\\text{sensory}}$ matrices.\n",
        "\n",
        "**Exercise** : Set up our `pykalman` `KalmanFilter` object with these settings using the code below. You can find the help for this library [here](https://pykalman.github.io/#kalman-filter-user-s-guide)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EtqSajSoWNU"
      },
      "source": [
        "# set up our KalmanFilter object and tell it which parameters we want to\n",
        "# estimate\n",
        "np.random.seed(1)\n",
        "\n",
        "n_dim_obs = 2\n",
        "n_dim_state = 2\n",
        "######################\n",
        "### your code here ###\n",
        "######################\n",
        "kf = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3EzoO0docVY"
      },
      "source": [
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/blob/master/Solutions/TP3Sol4.py) for solution.\n",
        "\n",
        "Because we know from the reported experimental design that subjects fixated in the center of the screen right before the image appears, we can set the initial starting state estimate $\\mu_0$ as being the center pixel of the stimulus image (the first data point in this sample dataset) with a correspondingly low initial noise covariance $\\Sigma_0$. Once we have everything set, it's time to fit some data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyLA1fwdoe2p"
      },
      "source": [
        "# Choose a subject and stimulus image\n",
        "subject_id = 1\n",
        "image_id = 2\n",
        "data = subjects[subject_id][image_id]\n",
        "\n",
        "# Provide the initial states\n",
        "kf.initial_state_mean = #fill here\n",
        "kf.initial_state_covariance = #fill here\n",
        "\n",
        "# Estimate the parameters from data using the EM algorithm\n",
        "#fill here\n",
        "\n",
        "print(f'F =\\n{kf.transition_matrices}')\n",
        "print(f'Q =\\n{kf.transition_covariance}')\n",
        "print(f'H =\\n{kf.observation_matrices}')\n",
        "print(f'R =\\n{kf.observation_covariance}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhvufExQoj9K"
      },
      "source": [
        "We see that the EM algorithm has found fits for the various dynamics parameters. One thing you will note is that both the state and observation matrices are close to the identity matrix, which means the x- and y-coordinate dynamics are independent of each other and primarily impacted by the noise covariances.\n",
        "\n",
        "We can now use this model to smooth the observed data from the subject. In addition to the source image, we can also see how this model will work with the gaze recorded by the same subject on the other images as well, or even with different subjects.\n",
        "\n",
        "Below are the three stimulus images overlayed with recorded gaze in magenta and smoothed state from the filter in green, with gaze begin (orange triangle) and gaze end (orange square) markers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r3ziGNEons0"
      },
      "source": [
        "#@title\n",
        "\n",
        "#@markdown Make sure you execute this cell to enable the widget!\n",
        "\n",
        "@widgets.interact(subject_id=widgets.IntSlider(1, min=0, max=4))\n",
        "def plot_smoothed_traces(subject_id=0):\n",
        "  subject = subjects[subject_id]\n",
        "  fig, axes = plt.subplots(ncols=3, figsize=(18, 4))\n",
        "  for data, img, ax in zip(subject, images, axes):\n",
        "    ax = plot_gaze_data(data, img=img, ax=ax)\n",
        "    plot_kf_state(kf, data, ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icf91DN_orT5"
      },
      "source": [
        "Why do you think one trace from one subject was sufficient to provide a decent fit across all subjects? If you were to go back and change the subject_id and/or image_id for when we fit the data using EM, do you think the fits would be different?\n",
        "\n",
        "Finally, recall that the orignial task was to use this data to help devlop models of visual salience. While our Kalman filter is able to provide smooth estimates of observed gaze data, it's not telling us anything about *why* the gaze is going in a certain direction. In fact, if we sample data from our parameters and plot them, we get what amounts to a random walk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXd5yXVSotbs"
      },
      "source": [
        "kf_state, kf_data = kf.sample(len(data))\n",
        "ax = plot_gaze_data(kf_data, img=images[2])\n",
        "plot_kf_state(kf, kf_data, ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTaNVZ9oowHI"
      },
      "source": [
        "This should not be surprising, as we have given the model no other observed data beyond the pixels at which gaze was detected. We expect there is some other aspect driving the latent state of where to look next other than just the previous fixation location.\n",
        "\n",
        "In summary, while the Kalman filter is a good option for smoothing the gaze trajectory itself, especially if using a lower-quality eye tracker or in noisy environmental conditions, a linear dynamical system may not be the right way to approach the much more challenging task of modeling visual saliency.\n"
      ]
    }
  ]
}