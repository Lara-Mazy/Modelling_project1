{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LGBIO2060_TP1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg1WKjlfQuXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Some helper functions\n",
        "\n",
        "def plot_my_gaussian(x,px):\n",
        "  \"\"\"\n",
        "  This function plots a Gaussian distribution\n",
        "\n",
        "  Inputs : x (numpy array) along which we want to represent the distribution\n",
        "           px(numpy array) values taken by the distribution\n",
        "  \"\"\"\n",
        "\n",
        "  fig, ax=plt.subplots()\n",
        "  ax.plot(x,px,'C1',LineWidth=2,label='Estimated state')\n",
        "  ax.axvline(x[px.argmax()],'C2',label='Latent state')\n",
        "  ax.legend()\n",
        "  ax.set_ylabel('Probability')\n",
        "  ax.set_xlabel('Value')\n",
        "\n",
        "  return ax"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKmvg4dBQvTT",
        "colab_type": "text"
      },
      "source": [
        "# LGBIO 2060 - Exercise session 1\n",
        "# Decision making - Sequential probability ratio test\n",
        "\n",
        "At the end of this session you should be able to : \n",
        "\n",
        "* Define and explain the concept of likelihood and how it can be related to biological systems\n",
        "\n",
        "* Explain the working principle of SPRT and its use in modelling decision making\n",
        "\n",
        "* Discuss the difference between time and threshold stopping criteria\n",
        "\n",
        "* Discuss the speed accuracy tradeoff in decision making"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiIIrg38RKLh",
        "colab_type": "text"
      },
      "source": [
        "# Part 1 : Gaussian distribution - Inferring the world through sensitive input\n",
        "When we try to estimate the exact position of our gaze or limb based on  sensory inputs (vision, proprioception), we always end up with an erroneous estimate. This means that, even though we have perfectly working sensory inputs, they are influenced by noise and therefore the inferred latent state will be a noisy approximation of the real latent state. For example, if the exact position of the tip of your fingernail in a given cartesian space is $[2 cm, 3cm]$, you might end up with an estimate which is $[1.95 cm, 3.07 cm]$ when you rely on sensory input to find it. \\\\\n",
        "\n",
        "\n",
        "The noisy observation of the latent state can be modelled by a Gaussian distribution whose mean is the value of the latent state and whose variance characterises the amount of noise present in the system. We can therefore write that the observation $y$ of the state $\\mu$ is such that :\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$\n",
        "y\\sim\\mathcal{N}\\left(\\mu,\\, \\sigma^2\\right)\n",
        "$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "\n",
        "As a reminder, au Gaussian distribution is characterised by the following equation : \\\\\n",
        "\n",
        "\n",
        "$$\\mathcal{N}\\left(\\mu,\\sigma^2\\right) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp\\left(\\frac{-\\left(x-\\mu\\right)^2}{2\\sigma^2}\\right)$$\n",
        "\n",
        "**Exercise 1**\n",
        "\n",
        "Implement a function that creates a gaussian distribution given its parameters and the *x* vector whose signature is given below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVyupXhkUqc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_gaussian(x_vector,mu,sigma):\n",
        "  \"\"\"\n",
        "  This function computes the Gaussian distribution of parameters mu and sigma \n",
        "  over the set x_vector\n",
        "  \n",
        "  Inputs :\n",
        "    x_vector is the set over which we want to evaluate the distribution\n",
        "    mu is the mean value of the distribution\n",
        "    sigma is the standard deviation of the distribution\n",
        "\n",
        "  Outputs : \n",
        "    px is a numpy array that contains the value of the distribution evaluate at \n",
        "    every points of the set x_vector\n",
        "  \"\"\"\n",
        "  ################\n",
        "  #your code here#\n",
        "  ################\n",
        "\n",
        "  return px"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ_uJsW1efLI",
        "colab_type": "text"
      },
      "source": [
        "**Run the cell below to test your code**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km5Ol50beDQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_vector= np.arange(-5,5,0.1)\n",
        "mu = 0; sigma = 0.1\n",
        "px = my_gaussian(x_vector,mu,sigma)\n",
        "fig, ax=plt.subplots()\n",
        "ax.plt(x_vector,px,'C1')\n",
        "ax.set_xlabel('Position')\n",
        "ax.set_ylabel('Probability')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiPj-_jnXp3D",
        "colab_type": "text"
      },
      "source": [
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/blob/Hakuri/Solutions/Exercise1Solution) for solution.\n",
        "\n",
        "\n",
        "Use the widget herebelow to investigate the impact of the mean and standard deviation on the shape of the gaussian distribution. \n",
        "\n",
        "\n",
        "**Make sure to execute the cell before playing with the widget**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7NLOnUlsCTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "cellView": "form",
        "outputId": "dc0e449b-4d35-4618-c396-7e5e3c73de32"
      },
      "source": [
        "#@title\n",
        "#@markdown Make sure you execute this cell to enable the widget\n",
        "\n",
        "x = np.arange(-10,11,0.1)\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def refresh(mu=1,sigma=1):\n",
        "  gaussian = my_gaussian(x_vector,mu,sigma)\n",
        "\n",
        "  ax = plot_my_gaussian(x_vector,gaussian)\n",
        "  plt.show()\n",
        "\n",
        "style = {'description_width' : 'initial'}\n",
        "\n",
        "_ = widgets.interact(refresh,\n",
        "    mu = widgets.FloatSlider(value=2, min=-10, max=10, steps=0.5, description=\"mu:\", style = style),\n",
        "    sigma = widgets.FloatSlider(value=0.5, min=0.5, max=10, steps=0.5, description=\"sigma\",style=style),\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ce169a3a3311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#@markdown Make sure you execute this cell to enable the widget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNA_YTl5Xx8U",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 : Sequential probability ratio test (SPRT) - Decision making\n",
        "\n",
        "Humans and animals are able to make decisions when they faced a binary alternative. In this section, we will model decision making using sequential probability ratio test (SPRT). This model can be used in a random dot motion task (see [here](https://www.youtube.com/watch?v=oDxcyTn-0os) for an example). In this paradigm, a patch of points moving either on average to the left or to the right is shown to the subject that has to determine the direction of movement. Subjects' goal is to determine the direction of the velocity which can be easy or though depending on the coherence of each individual point.\n",
        "\n",
        "**Ins√©rer image ici**\n",
        "\n",
        "In this tutorial, we consider a simplified version of the random dot motion task. On each trial $i$, the subject is shown a single dot moving at velocity $v_i$ generated by a fixed probability distribution, which we know to be either: \n",
        "\n",
        "\n",
        "$$\n",
        "\\\\\n",
        "\\begin{eqnarray}\n",
        "p_L &=& \\mathcal{N}\\left(-1,\\sigma^2\\right)\\\\\n",
        "&& \\textrm{or}\\\\\n",
        "p_R &=& \\mathcal{N}\\left(+1,\\sigma^2\\right)\\\\\n",
        "\\end{eqnarray}\n",
        "$$\n",
        "\n",
        "This means that the dot is moving leftward or rightward and that its speed is normally distributed around $|1|$. We want to determine which distribution amongst $p_L$ and $p_R$ is the true data generating distribution (in other words, we want to determine whether the point is moving to the right or to the left). In order to do that, we will define two alternative hypotheses, the first one $H_L$ states that $p_L$ is the data generating distribution while $H_R$ states that it is $p_R$.\n",
        "\n",
        "To decide which hypothesis is true, we will comparte the likelihood that the data is generated by the two probability distributions defined above. We will define the concept of likelihood that tells us how likely it is that a given data point is generated from a given distribution. For a given occurence of the point $x_i$, the two likelihood functions will be defined by $p_L\\left(x_i|z=0\\right)$ and $p_R\\left(x_i|z=1\\right)$, which are two gaussian distributions.\n",
        "\n",
        "\n",
        "Using the following gaussian observations models\n",
        "\n",
        "$$\\begin{eqnarray}\n",
        "p_L\\left(x_i|z=0\\right) & = & \\mathcal{N}\\left(\\mu_L,\\sigma_L^2\\right)\\\\\n",
        "p_R\\left(x_i|z=1\\right) & = & \\mathcal{N}\\left(\\mu_R,\\sigma_R^2\\right)\\\\\n",
        "\\end{eqnarray}\n",
        "$$\n",
        "\n",
        "and the definition of the log-likelihood ratio is \n",
        "\n",
        "$$\n",
        "\\Lambda_i = \\dfrac{p_L\\left(x_i|z=0\\right)}{p_R\\left(x_i|z=1\\right)}\n",
        "$$\n",
        "**Thanks to the definition of Gaussian distribution, compute the expression of $\\log \\Lambda_i$ in terms of $\\mu_L$, $\\mu_R$, $\\sigma_R$ and $\\sigma_R$.** \n",
        "\n",
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/blob/Hakuri/Solutions/Tuto1SolLikelihood) for solution\n",
        "\n",
        "\n",
        "Without loss of generality, let us further assume that the true data generating distribution is $p_R$ (this means the dot is moving to the right). In this case $x_i$ can be expressed as $x_i = \\mu_R + \\sigma_R \\epsilon$ where $\\epsilon$ comes from a standard Gaussian. The foregoing formula can then be rewritten as\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$\n",
        "\\log \\Lambda_i = \\left( \\log\\dfrac{\\sigma_L}{\\sigma_R} + 0.5\\dfrac{\\left(\\mu_R-\\mu_L\\right)^2}{\\sigma_L^2}\\right) + \\left(\\dfrac{\\mu_L-\\mu_R}{\\sigma_L^2}\\sigma_R\\,\\epsilon - 0.5\\left[1-\\left(\\dfrac{\\sigma_R}{\\sigma_L}\\right)^2\\right]\\epsilon^2\\right)\n",
        "$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "Where the first two constant terms serve as the drifting part and the last terms are the diffusion part. If we further let $\\sigma_L = \\sigma_R$, we can get rid of the quadratic term and this reduces to the classical discrete drift-diffusion equation:\n",
        "\n",
        "$$\n",
        "\\log \\Lambda_i = 0.5\\dfrac{\\left(\\mu_R - \\mu_L\\right)^2}{\\sigma^2} + \\dfrac{\\mu_R - \\mu_L}{\\sigma_L^2}\\epsilon, \\,\\,\\,\\,\\, \\text{where } \\epsilon\\sim\\mathcal{N}\\left(0,1\\right)\n",
        "$$\n",
        "\n",
        "**Implement the sequential probability ratio test in the function compute_SPRT whose signature is given below.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nuwv7vf6uIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "4d74c35a-eb39-4959-b2d8-55b122579489"
      },
      "source": [
        "def compute_SPRT(sigma,true_dist=1,data):\n",
        "    \"\"\"\n",
        "  Computes the time evolution of the likelihood ratio between left & right hypothesis\n",
        "\n",
        "  Inputs : \n",
        "    sigma (double) :  standard deviation (noise around the real direction value)\n",
        "    true_dist (0 or 1) : Which state is the true state.\n",
        "    data is the true data\n",
        "\n",
        "  Returns : \n",
        "    evidence_history (numpy vector) : the history of cumulated evidence given\n",
        "                                      generated data\n",
        "    decision (int) : 1 for pR, 0 for pL\n",
        "    data (numpy vector) : the generated sequences of data in this trial\n",
        "  \"\"\"\n",
        "  muL = -1.0; muR =1\n",
        "  pL = stats.norm(loc=muL,scale=sigma)\n",
        "  pR = stats.norm(loc=muR,scale=sigma)\n",
        "  ##################\n",
        "  # your code here #\n",
        "  ##################\n",
        "  \n",
        "    \n",
        "  return evidence_history, decision\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-69a627ca338b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0msimulate_and_plot_SPRT_fixedtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# function to create!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'simulate_and_plot_SPRT_fixedtime' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGHamr24rhJj",
        "colab_type": "text"
      },
      "source": [
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/blob/Hakuri/Solutions/Exercise2Solution) for solution\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this first example, the decision is made after a given time (that may be very long); this is not always the optimal way to stop the drift diffusion model. In the next section, we will investigate another stopping criterion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkr6CZHmY_Jy",
        "colab_type": "text"
      },
      "source": [
        "**Run the cell below to test your code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwJImChDYIaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing code for the SPRT implementation\n",
        "\n",
        "np.random.seed(1000)\n",
        "sigma = 3.5\n",
        "num_sample = 100\n",
        "stop_time = 150\n",
        "\n",
        "evidence_history_list = []\n",
        "\n",
        "for ii in range(num_sample):\n",
        "    evidence_history,decision = compute_SPRT(sigma,1,data)\n",
        "    evidence_history_list.append(evidence_history)\n",
        "    \n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(np.zeros(np.max(len,evidence_history_list)))\n",
        "for evidences in evidence_history_list:\n",
        "    ax.plot(np.arange(len(evidences)),evidences)\n",
        "    ax.set_xlabel(\"Time\")\n",
        "    ax.set_ylabel(\"Cumulated log likelihood ratio\")\n",
        "    ax.set_title(\"Log likelihood ratio trajectories under the fixed-time condition\")\n",
        "plt.show(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMFJ27i1YzGs",
        "colab_type": "text"
      },
      "source": [
        "# Part 4 : Drift diffusion model with fixed threshold\n",
        "\n",
        "\n",
        "The thresholding stopping rule defined a desire error rate and will continue making measurements until that error rate is reached. Experimental evidence suggested that evidence accumulation and thresholding stopping strategy happens at neuronal level (see [this article](tospoiler) for further reading).\n",
        "\n",
        "In this exercise, we will use thresholding as our stopping rule and observe the behavior of the DDM. \n",
        "\n",
        "With thresholding stopping rule, we define a desired error rate and will continue making measurements until that error is reached. Experimental evidence suggested that evidence accumulation and thresholding stopping strategy happen at neuronal level.\n",
        "\n",
        "Mathematically speaking, the threshold is defined based on the likelihood ratio that has been computed before. We define the error rate $\\alpha$ that we want to accept. Based on the properties of probability, we have the following definition of thresholds:\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray}\n",
        "th_L = \\log \\dfrac{\\alpha}{1-\\alpha} & = & -th_R\\\\\n",
        "th_R = \\log \\dfrac{1-\\alpha}{\\alpha} & = & -th_L\n",
        "\\end{eqnarray}\n",
        "$$\n",
        "\n",
        "Implement the function *threshold_DDM* whose signature is given below :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZD1DxQm-Qh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_SPRTT(sigma,true_dist,data,alpha):\n",
        "  \"\"\"\n",
        "  This function performs the SPRT with thresholding stopping criterion\n",
        "\n",
        "  Inputs : sigma (float) is the standard deviation of both distributions\n",
        "           true_dist (int) is the data generating distribution\n",
        "           alpha (float) is the accuracy level we want to reach (in other words this is the percentage of type I error that we allow)\n",
        "\n",
        "  Outputs : evidence_history(numpy array) contains the evidence accumulation\n",
        "            decision (int) is the decision taken by the subject\n",
        "  \"\"\"\n",
        "    muL = -1.0; muR =\n",
        "    pL = stats.norm(loc=muL,scale=sigma)\n",
        "    pR = stats.norm(loc=muR,scale=sigma)\n",
        "    evidence_history = []\n",
        "    current_evidence = 0.0\n",
        "    threshold_reached = False\n",
        "    threshold = ...\n",
        "\n",
        "    ##################\n",
        "    # your code here #\n",
        "    ##################\n",
        "    \n",
        "    return evidence_history,decision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQl2ZKdden_X",
        "colab_type": "text"
      },
      "source": [
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/blob/Hakuri/Solutions/Exercise3Solution) for solution\n",
        "\n",
        "**Run the cell below to test your code**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6WBgZYPeoK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1000)\n",
        "sigma = 3.5\n",
        "num_sample = 100\n",
        "stop_time = 150\n",
        "\n",
        "evidence_history_list = []\n",
        "\n",
        "for ii in range(num_sample):\n",
        "    evidence_history,decision = compute_SPRT(sigma,1,data)\n",
        "    evidence_history_list.append(evidence_history)\n",
        "    \n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(np.zeros(np.max(len,evidence_history_list)))\n",
        "for evidences in evidence_history_list:\n",
        "    ax.plot(np.arange(len(evidences)),evidences)\n",
        "    ax.set_xlabel(\"Time\")\n",
        "    ax.set_ylabel(\"Cumulated log likelihood ratio\")\n",
        "    ax.set_title(\"Log likelihood ratio trajectories under the fixed-time condition\")\n",
        "plt.show(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-CN1piiYzQE",
        "colab_type": "text"
      },
      "source": [
        "# Part 5 : Accuracy vs. Threshold\n",
        "\n",
        "The faster you make a decision, the lower your accuracy often is. This phenomenon is known as the **speed/accuracy tradeoff**. Humans can make this tradeoff in a wide range of situtations as many animal species, including ants, bees, rodents, and monkeys also show similar effects.\n",
        "\n",
        "To illustrate the speed/accuracy tradeoff under thresholding stopping rule, let's run some simulations under different thresholds and look at how average decision speed (1/length) changes with average decision accuracy. We used speed rater than accuracy because in real experiments, subjects can be incetivized to respond faster or slower, it's much harder to precisely control their deicison time or error threshold.\n",
        "\n",
        "*     Complete the function simulate_accuracy_vs_threshold to simulate and compute accuracies vs. average decision lengths for a list of error thresholds. You will need to supply code to calculate average decision \"speed\" from the lengts of trials. You should also calculate the overall accuracy across these trials.\n",
        "\n",
        "*      We've set up a list of error thresholds. Run repeated simulations and collect average accuracy with average length for each error rate in this list, and use our provided code to visualize the speed/accuracy tradeoff. You should see a positive correlation between length and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYO3Si7XFBF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sa_tradeoff(alpha_vector,sigma,true_dist=1):\n",
        "  \"\"\"\n",
        "  This function computes the speed accuracy tradeoff\n",
        "  Authors : Florence Blondiaux & Antoine de Comite \n",
        "\n",
        "  Inputs : alpha_vector (numpy array) contains the vector of accuracy criteria \n",
        "           sigma (float) is the standard deviation of both distribution\n",
        "           true_dist (int) is the correct distribution\n",
        "  \n",
        "  Outputs : length_iter (numpy vector) contains the time needed to reach every accuracy\n",
        "  \"\"\"\n",
        "  # Your code goes here\n",
        "\n",
        "  return length_iter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zVEJ3EYHFS-",
        "colab_type": "text"
      },
      "source": [
        "Click [here](https://github.com/fblondiaux/LGBIO2060-2020/edit/Hakuri/Solutions/Exercise4Solution) for solution\n",
        "\n",
        "**Run the cell below to test your code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASj4s_Mz3L64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sigma = 3.5    \n",
        "alpha_vector = np.arange(0.01,0.2,0.01)\n",
        "length_iter = sa_tradeoff(alpha_vector,sigma,true_dist=1)\n",
        "\n",
        "\n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(alpha_vector, 1/length_iter,'C1',Linewidth=2)\n",
        "ax.set_xlabel(\"Accuracy\")\n",
        "ax.set_ylabel(\"Speed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81UL8pvfYzXc",
        "colab_type": "text"
      },
      "source": [
        "# BONUS : Urgency gating\n",
        "\n",
        "**TODO**"
      ]
    }
  ]
}